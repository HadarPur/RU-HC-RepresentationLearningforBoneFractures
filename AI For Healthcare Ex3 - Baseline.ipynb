{"cells":[{"cell_type":"markdown","metadata":{"id":"MftOkY7eMkAC"},"source":["# **Exercise 3: Representation learning for bone fractures**\n","\n","## Overview\n","\n","In this assignment you are required to implement a bone fracture xray classification task utilizing a SSL approach with the following data set: https://stanfordmlgroup.github.io/competitions/mura/\n","\"MURA is a dataset of musculoskeletal radiographs consisting of 14,863 studies from 12,173 patients, with a total of 40,561 multi-view radiographic images. Each belongs to one of seven standard upper extremity radiographic study types: elbow, finger, forearm, hand, humerus, shoulder, and wrist. Each study was manually labeled as normal or abnormal by board-certified radiologists from the Stanford Hospital .\n","To evaluate models and get a robust estimate of radiologist performance, we collected additional labels from six board-certified Stanford radiologists on the test set, consisting of 207 musculoskeletal studies.\"\n","\n","<img src=\"https://github.com/HadarPur/RU-HC-RepresentationLearningforBoneFractures/blob/main/figures/radiologist_result_example.png?raw=true\" alt=\"Image\" style=\"max-width: 500px;\" />\n","\n","## Steps\n","1. Please perform data exploration and create a naÃ¯ve baseline (e.g. can be done based on the paper https://arxiv.org/abs/1712.06957, or any another approach you wish).\n","All steps must include a description of data exploration: data distribution, visualization, thorough evaluation, visualization of results, demonstration of good and bad results.\n","You can focus on the 3 different bones for example â€“ Elbow, Hand and Shoulder as was done in the example https://github.com/Alkoby/Bone-Fracture-Detection:\n","- <img src=\"https://github.com/HadarPur/RU-HC-RepresentationLearningforBoneFractures/blob/main/figures/visualization_example.png?raw=true\" alt=\"Image\" style=\"max-width: 300px;\" />\n","\n","2.  Implement one of the following representation learning approaches listed below and provide a detailed explanation of your approach compared to the baseline (e.g. compare the results when using of 1%,10%,100% of the labeled data as done in https://arxiv.org/pdf/2006.10029.pdf).\n","  * SimCLR Chen et al. https://github.com/google-research/simclr\n","  * Byol Grill et al.https://papers.nips.cc/paper/2020/file/f3ada80d5c4ee70142b17b8192b2958e-Paper.pdf\n","  * Moco He et al. https://arxiv.org/pdf/1911.05722.pdf\n","  * SimSiam Chen et al. https//arxiv.org/abs/2011.10566\n"]},{"cell_type":"markdown","metadata":{"id":"jpbMTsCd6a8Y"},"source":[" <font color=\"Burgundy\" size=5> ðŸ’¡ **important-**</font> please note that if you want to run the notebook it's better to:\n"," 1. restart runtime and than compile from start until baseline (including) sections\n"," 2. run only the part you would like to examine (shoulder, hand, elbow)\n"," 3. after each run restart runtime and go over steps 1,2"]},{"cell_type":"markdown","metadata":{"id":"fL_RbmCFON4R"},"source":["# Submitted\n","\n","*   Shir Nitzan\n","*   Timor Baruch\n","*   Hadar Pur"]},{"cell_type":"markdown","metadata":{"id":"B2Ovc12ZMCVz"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7G6jza-UjYM"},"outputs":[],"source":["!pip install torch torchvision pytorch-lightning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZLl8Mq__qXK"},"outputs":[],"source":["import os\n","import torch\n","import multiprocessing\n","import scipy.ndimage\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pytorch_lightning as pl\n","import torch.optim as optim\n","\n","from tqdm import tqdm\n","from google.colab import drive\n","from collections import Counter\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from PIL import Image\n","from torch.autograd import Variable\n","from psutil import virtual_memory\n","from tabulate import tabulate\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from torchmetrics import Accuracy, Precision, Recall, F1Score\n","from torchvision.models import densenet169\n","from torchvision.transforms.functional import pad\n","from PIL import Image\n","from pytorch_lightning.loggers import TensorBoardLogger"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qEtPtH4d-PqQ"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qYQKOPBO-g7s"},"outputs":[],"source":["mura_v11_path = '/content/MURA-v1.1'\n","if os.path.exists(mura_v11_path) == False:\n","  !gdown 1XjMNPle9fO2NATeXtrIgz6h03LCrwOvN\n","  !unzip -q '/content/MURA-v1.1.zip'\n","  print(\"Done unzip\")\n","else:\n","  print(\"Data exist, continue\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LDwl18nyMGpT"},"outputs":[],"source":["print(torch.__version__, torch.cuda.is_available())"]},{"cell_type":"markdown","metadata":{"id":"NMqqVfWjMQVb"},"source":["## Memory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4kMpn-dpMRD6"},"outputs":[],"source":["ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"markdown","metadata":{"id":"rtWiN1FoMTGA"},"source":["## GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PxcuQioJMX8X"},"outputs":[],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v3RwhuyeMYeD"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bi9yY5A9Maem"},"outputs":[],"source":["max_workers = multiprocessing.cpu_count()\n","print(\"Maximum number of workers:\", max_workers)"]},{"cell_type":"markdown","metadata":{"id":"g3SPkYE1McuL"},"source":["## Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ETSaMWdMFiOd"},"outputs":[],"source":["pd.set_option('display.max_colwidth', None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"atHHL-qJOsfl"},"outputs":[],"source":["class DatasetPath:\n","    def __init__(self, dataset_dir):\n","        self.dataset_dir = dataset_dir\n","        self.train_csv_path = f'{dataset_dir}/train_labeled_studies.csv'\n","        self.test_csv_path = f'{dataset_dir}/valid_labeled_studies.csv'\n","\n","class ImageProcessor:\n","    def __init__(self, directory):\n","        self.directory = directory\n","\n","    def get_paths(self):\n","        image_paths = []\n","        for root, dirs, files in os.walk(self.directory):\n","            image_paths.extend([os.path.join(root, file) for file in files if file.endswith('.png') and file.startswith('image')])\n","        return image_paths\n","\n","class DataTransformer:\n","    def __init__(self, df):\n","        self.df = df\n","\n","    def transform_df(self):\n","        ts_rows = [{'path': image_path, 'label': row['label']}\n","                    for _, row in self.df.iterrows()\n","                    for image_path in ImageProcessor(row['path']).get_paths()]\n","        return pd.DataFrame(ts_rows, columns=['path', 'label'])\n","\n","    def transform_ds(self):\n","        dataset = [(ImageProcessor(row['path']).get_paths(), row['label']) for _, row in self.df.iterrows()]\n","        label_count = Counter(row['label'] for _, row in self.df.iterrows())\n","        return dataset, label_count\n","\n","class BodyPartExtractor:\n","    @staticmethod\n","    def extract(path):\n","        split_path = path.split(\"/\")\n","        return next((part[3:] for part in split_path if \"XR_\" in part), None)\n","\n","class DataframeGenerator:\n","    def __init__(self):\n","        pass\n","\n","    def generate_df(self, path, body_parts, flat=False):\n","        df = pd.read_csv(path, header=None, names=['path', 'label'])\n","        if flat:\n","            df = DataTransformer(df).transform_df()\n","\n","        df['body_part'] = df['path'].apply(BodyPartExtractor.extract)\n","        df = df[df['body_part'].isin(body_parts)]\n","        return df\n","\n","    def create_body_df(self, path, body_parts):\n","      datasets = {}\n","\n","      for body_part in body_parts:\n","          df = self.generate_df(path, [body_part]).drop(['body_part'], axis=1)\n","          datasets[body_part] = df\n","\n","      return datasets[body_parts[0]], datasets[body_parts[1]], datasets[body_parts[2]]"]},{"cell_type":"markdown","metadata":{"id":"SiE02ZejqjSC"},"source":["## Data distribution"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbCvqpygqip5"},"outputs":[],"source":["class SummaryGenerator:\n","    @staticmethod\n","    def generate_table(df):\n","        summary = df.groupby(['body_part', 'label']).size().unstack(fill_value=0)\n","        summary['Total'] = summary.sum(axis=1)\n","        summary.columns = ['Normal', 'Abnormal', 'Total']\n","        summary = summary.reset_index().rename(columns={'body_part': 'Part'})\n","        summary = summary.sort_values('Part')\n","\n","        summary.style.set_properties(**{'text-align': 'left'})\n","\n","        return summary\n","\n","    @staticmethod\n","    def plot_summary_table(df, title):\n","        summary = SummaryGenerator.generate_table(df)\n","        melted_df = summary.melt(id_vars='Part', var_name='Label', value_name='Count')\n","\n","        colors = ['#747FE3', '#8EE35D', '#E37346']\n","        sns.set_palette(colors)  # Set the color palette\n","\n","        sns.set_style('darkgrid')\n","        sns.barplot(data=melted_df, x='Part', y='Count', hue='Label')  # Use the palette colors\n","        plt.xlabel('Body Part')\n","        plt.ylabel('Count')\n","        plt.title(f'Distribution of Labels by Body Part - {title}')\n","        plt.legend(title='')\n","        plt.xticks(rotation=15)\n","        plt.show()"]},{"cell_type":"markdown","metadata":{"id":"252oreHMhUIQ"},"source":["## Data Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bWJHg3EUjM30"},"outputs":[],"source":["class ImageDisplay:\n","    @staticmethod\n","    def display(df, body_part, title):\n","        normal_df = df[(df['label'] == 0) & (df['body_part'] == body_part)].sample(5).reset_index(drop=True)\n","        abnormal_df = df[(df['label'] == 1) & (df['body_part'] == body_part)].sample(5).reset_index(drop=True)\n","\n","        fig, axs = plt.subplots(nrows=2, ncols=5, figsize=(12, 6))\n","        axs[0, 0].set_ylabel(\"Normal\", fontsize=15)\n","        axs[1, 0].set_ylabel(\"Abnormal\", fontsize=15)\n","\n","        for i, row in normal_df.iterrows():\n","            image_path = row['path']\n","            # print(f'normal_df image_path = {image_path}')\n","            image = Image.open(image_path)\n","            axs[0, i].imshow(image, cmap='gray')\n","            axs[0, i].grid(False)\n","\n","        for i, row in abnormal_df.iterrows():\n","            image_path = row['path']\n","            # print(f'abnormal_df image_path = {image_path}')\n","            image = Image.open(image_path)\n","            axs[1, i].imshow(image, cmap='gray')\n","            axs[1, i].grid(False)\n","\n","        fig.suptitle(title, fontsize=20)\n","        plt.tight_layout()\n","\n","        plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ufhQFAMdlJWp"},"source":["## Data Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"733O7O_YlP8h"},"outputs":[],"source":["class ImageAugmentor:\n","    def __init__(self, do_flip=True, do_rotate=True, do_scale=False, do_translate=True):\n","        self.do_flip = do_flip\n","        self.do_rotate = do_rotate\n","        self.do_scale = do_scale\n","        self.do_translate = do_translate\n","\n","        self.transformer = []\n","\n","    def augment(self):\n","        if self.do_flip:\n","            self.transformer.append(self.flip())\n","        if self.do_rotate:\n","            self.transformer.append(self.rotate())\n","        if self.do_scale:\n","            self.transformer.append(self.scale())\n","        if self.do_translate:\n","            self.transformer.append(self.translate())\n","        return self.transformer\n","\n","    def flip(self):\n","        return transforms.RandomHorizontalFlip()\n","\n","    def rotate(self):\n","        return transforms.RandomRotation(10)\n","\n","    def scale(self):\n","        return transforms.Resize((128, 128))\n","\n","    def translate(self):\n","        return transforms.ToTensor()"]},{"cell_type":"markdown","metadata":{"id":"bXoAY9RYlSZx"},"source":["## Data Normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uMyPBkK9lVS-"},"outputs":[],"source":["class ImageNormalizer:\n","    def __init__(self, normalization_type=\"none\"):\n","        assert normalization_type in [\"zscore\", \"percentile\", \"none\"], \"Invalid normalization type\"\n","        self.normalization_type = normalization_type\n","\n","    def normalize(self):\n","        if self.normalization_type == \"zscore\":\n","            return self.z_score_normalization()\n","        elif self.normalization_type == \"percentile\":\n","            return self.percentile_normalization()\n","        elif self.normalization_type == \"none\":\n","            return []\n","\n","    def z_score_normalization(self):\n","        return [transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n","\n","    def percentile_normalization(self):\n","        return [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]"]},{"cell_type":"markdown","metadata":{"id":"djnr2w5ZaFgb"},"source":["## Preparing Data\n","The body parts are ['ELBOW', 'HAND', 'SHOULDER']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lNsdlrLrRe6O"},"outputs":[],"source":["dataset_dir = '/content/MURA-v1.1'\n","dataset = DatasetPath(dataset_dir)\n","print(dataset.train_csv_path)\n","print(dataset.test_csv_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WVKYnVVLRxca"},"outputs":[],"source":["body_parts = ['ELBOW', 'HAND', 'SHOULDER']\n","dataframe_generator = DataframeGenerator()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B5QLDlT2owvB"},"outputs":[],"source":["train_df = dataframe_generator.generate_df(dataset.train_csv_path, body_parts, flat=True)\n","print(f'train_df = {len(train_df)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pmFLGbvqo7II"},"outputs":[],"source":["test_df = dataframe_generator.generate_df(dataset.test_csv_path, body_parts, flat=True)\n","print(f'test_df = {len(test_df)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wrsRVbHpoz29"},"outputs":[],"source":["train_df_elbow, train_df_hand, train_df_shoulder = dataframe_generator.create_body_df(dataset.train_csv_path, body_parts)\n","test_df_elbow, test_df_hand, test_df_shoulder = dataframe_generator.create_body_df(dataset.test_csv_path, body_parts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3UZ0xvuQ_avu"},"outputs":[],"source":["print(len(train_df_elbow))"]},{"cell_type":"markdown","metadata":{"id":"cmqM4sOKrX9w"},"source":["#### Training Data Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vLMs200Kf04T"},"outputs":[],"source":["train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5NdxougUnKrU"},"outputs":[],"source":["SummaryGenerator.generate_table(train_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6tbEnrDhtxmj"},"outputs":[],"source":["SummaryGenerator.plot_summary_table(train_df, 'train')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nggEJlTALrxH"},"outputs":[],"source":["train_df_elbow.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IfBNSy60Vcpz"},"outputs":[],"source":["ImageDisplay.display(df = train_df, body_part = body_parts[0], title = \"Train Data - Elbow\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eX_A9UFcol9E"},"outputs":[],"source":["train_df_hand.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8lsSZORaVlqP"},"outputs":[],"source":["ImageDisplay.display(df = train_df, body_part = body_parts[1], title = \"Train Data - Hand\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8yRYV_Xaon2d"},"outputs":[],"source":["train_df_shoulder.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mcDwPQtNVtVS"},"outputs":[],"source":["ImageDisplay.display(df = train_df, body_part = body_parts[2], title = \"Train Data - Shoulder\")"]},{"cell_type":"markdown","metadata":{"id":"ulJXfES4aaaK"},"source":["#### Test Data Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yv2kMXA6f8xh"},"outputs":[],"source":["test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rpwxxfXFqVJm"},"outputs":[],"source":["SummaryGenerator.generate_table(test_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MX0BXKFN49QZ"},"outputs":[],"source":["SummaryGenerator.plot_summary_table(test_df, 'validation')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"knMRZu-Madcm"},"outputs":[],"source":["test_df_elbow.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nAjYb6pjVznI"},"outputs":[],"source":["ImageDisplay.display(df = test_df, body_part = body_parts[0], title = \"Test Data - Elbow\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dtEH_cV4oz5h"},"outputs":[],"source":["test_df_hand.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gu21B54AV4UZ"},"outputs":[],"source":["ImageDisplay.display(df = test_df, body_part = body_parts[1], title = \"Test Data - Hand\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SgBiFabgo1Ob"},"outputs":[],"source":["test_df_shoulder.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_K41JQjwV9J2"},"outputs":[],"source":["ImageDisplay.display(df = test_df, body_part = body_parts[2], title = \"Test Data - Shoulder\")"]},{"cell_type":"markdown","metadata":{"id":"FqbdhY0fhChX"},"source":["## Baseline\n","To build the naive baseline we used the following references:\n","\n","\n","*   https://github.com/pyaf/DenseNet-MURA-PyTorch.git\n","*   https://github.com/Hawk453/MURA-DenseNet-Humerus.git\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b4v85hVAdOr2"},"outputs":[],"source":["class Baseline(Dataset):\n","    def __init__(self, data, transform=None):\n","        self.transform = transform\n","        self.dataset, self.label_count = DataTransformer(data).transform_ds()\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def get_label_weight(self, label):\n","        return self.label_count[label] / len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        image_paths, label = self.dataset[idx]\n","        images = [self.transform(Image.open(image_path).convert(\"RGB\")) if self.transform else Image.open(image_path).convert(\"RGB\") for image_path in image_paths]\n","        images = torch.stack(images)\n","        return images, len(image_paths), label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OkNSj0yWdQuT"},"outputs":[],"source":["class Loss(nn.Module):\n","    def __init__(self, Wt1, Wt0):\n","        super(Loss, self).__init__()\n","        self.Wt1 = Wt1\n","        self.Wt0 = Wt0\n","\n","    def forward(self, y_hat, y):\n","        loss = torch.mean(-(self.Wt1 * y * y_hat.log() + self.Wt0 * (1 - y) * (1 - y_hat).log()))\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k7oonG0tVxxn"},"outputs":[],"source":["class DenseNet169(nn.Module):\n","    def __init__(self):\n","        super(DenseNet169, self).__init__()\n","        self.model = densenet169(pretrained=True)\n","        num_ftrs = self.model.classifier.in_features\n","        self.model.classifier = nn.Sequential(\n","            nn.Linear(num_ftrs, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, views_x, n_views):\n","        batch_size, padded_views, c, w, h = views_x.size()\n","        views_x = views_x.view(-1, c, w, h)\n","\n","        multi_view_outputs = self.model(views_x)\n","        multi_view_outputs = multi_view_outputs.view(batch_size, padded_views)\n","\n","        outputs = torch.sum(multi_view_outputs * n_views, dim=1) / torch.sum(n_views, dim=1)\n","\n","        return outputs\n","\n","class LightingDenseNet(pl.LightningModule):\n","    def __init__(self, loss):\n","        super(LightingDenseNet, self).__init__()\n","        self.densenet_model = DenseNet169()\n","        self.loss = loss\n","        self.metrics = {\n","            \"accuracy\": Accuracy(task=\"binary\"),\n","            \"precision\": Precision(task=\"binary\"),\n","            \"recall\": Recall(task=\"binary\"),\n","            \"f1_score\": F1Score(task=\"binary\"),\n","        }\n","\n","    def forward(self, views_x, n_views):\n","        return self.densenet_model(views_x, n_views)\n","\n","    def training_step(self, batch, batch_idx):\n","        views_x, n_views, y = batch\n","\n","        y_hat = self(views_x, n_views)\n","        loss = self.loss(y_hat, y)\n","\n","        self.log('train_loss', loss)\n","        for metric_name, metric in self.metrics.items():\n","            self.log(f'train_{metric_name}', metric(y_hat.cpu(), y.cpu()))\n","\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        views_x, n_views, y = batch\n","\n","        y_hat = self(views_x, n_views)\n","        loss = self.loss(y_hat, y)\n","\n","        self.log('val_loss', loss)\n","        for metric_name, metric in self.metrics.items():\n","            self.log(f'val_{metric_name}', metric(y_hat.cpu(), y.cpu()))\n","\n","    def configure_optimizers(self):\n","        return optim.Adam(self.parameters(), lr=2e-5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BljDDYrddXEz"},"outputs":[],"source":["class DataLoaderManager:\n","    def __init__(self,batch_size=8, num_workers=4):\n","        self.batch_size = batch_size\n","        self.num_workers = num_workers\n","\n","    def get_train_transformer(self):\n","        image_augmentation = ImageAugmentor(do_flip=True, do_rotate=True, do_scale=True, do_translate=True).augment()\n","        image_normalization = ImageNormalizer(normalization_type = \"zscore\").normalize()\n","        return transforms.Compose(image_augmentation + image_normalization)\n","\n","    def get_test_transformer(self):\n","        image_augmentation = ImageAugmentor(do_flip=False, do_rotate=False, do_scale=True, do_translate=True).augment()\n","        image_normalization = ImageNormalizer(normalization_type = \"zscore\").normalize()\n","        return transforms.Compose(image_augmentation + image_normalization)\n","\n","    @staticmethod\n","    def collate_fn(batch):\n","        max_views = max([item[0].shape[0] for item in batch])\n","        images_list, n_views_list, labels_list = [], [], []\n","\n","        for item in batch:\n","            images, n_views, label = item\n","            images = nn.functional.pad(images, (0, 0, 0, 0, 0, 0, 0, max_views - images.shape[0]))\n","            images_list.append(images)\n","            n_views_list.append([1] * n_views + [0] * (max_views - n_views))\n","            labels_list.append(label)\n","\n","        images_tensor = torch.stack(images_list)\n","        n_views_tensor = torch.tensor(n_views_list)\n","        labels_tensor = torch.tensor(labels_list)\n","\n","        return images_tensor, n_views_tensor, labels_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VY62muvcdZ_w"},"outputs":[],"source":["class TrainerManager:\n","    def __init__(self, max_epochs=10):\n","        self.max_epochs = max_epochs\n","\n","    def train(self, model, train_loader, val_loader, dir_path):\n","        logger = TensorBoardLogger(save_dir=dir_path, name=\"MORA V1.1\")\n","\n","        self.trainer = pl.Trainer(max_epochs=self.max_epochs, logger=logger)\n","        self.trainer.fit(model, train_loader, val_loader)\n","\n","    def validate(self, model, test_loader):\n","        self.trainer.validate(model, test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4DaAdr9kYf6C"},"outputs":[],"source":["data_loader_manager = DataLoaderManager(batch_size=8, num_workers=4)\n","\n","train_val_transformer = data_loader_manager.get_train_transformer()\n","test_transformer = data_loader_manager.get_test_transformer()"]},{"cell_type":"markdown","metadata":{"id":"sso_0Pu1JbGb"},"source":["### Elbow"]},{"cell_type":"markdown","metadata":{"id":"VIhQpCJYeF6c"},"source":["#### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mtbeBuyKfpaG"},"outputs":[],"source":["train_df_elbow, val_df_elbow = train_test_split(train_df_elbow, test_size=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IAnfBKrWZBWq"},"outputs":[],"source":["train_dataset_elbow = Baseline(train_df_elbow, transform=train_val_transformer)\n","val_dataset_elbow = Baseline(val_df_elbow, transform=test_transformer)\n","test_dataset_elbow = Baseline(test_df_elbow, transform=test_transformer)\n","\n","train_loader_elbow = torch.utils.data.DataLoader(train_dataset_elbow, collate_fn=data_loader_manager.collate_fn,\n","                                           batch_size=8, shuffle=True, num_workers=6)\n","val_loader_elbow = torch.utils.data.DataLoader(val_dataset_elbow, collate_fn=data_loader_manager.collate_fn,\n","                                         batch_size=16, num_workers=6)\n","test_loader_elbow = torch.utils.data.DataLoader(test_dataset_elbow, collate_fn=data_loader_manager.collate_fn,\n","                                         batch_size=16, num_workers=6)\n","\n","loss_elbow = Loss(train_dataset_elbow.get_label_weight(1), train_dataset_elbow.get_label_weight(0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4K0TlASPdnSj"},"outputs":[],"source":["model_elbow = LightingDenseNet(loss_elbow)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGKjD1nudoqz"},"outputs":[],"source":["elbow_path = '/content/baseline/training/elbow'\n","trainer_manager_elbow = TrainerManager(max_epochs=15)\n","trainer_manager_elbow.train(model_elbow, train_loader_elbow, val_loader_elbow, elbow_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MeWux2bdgY-q"},"outputs":[],"source":["# Start tensorboard.\n","%load_ext tensorboard\n","%tensorboard --logdir /content/baseline/training/elbow"]},{"cell_type":"markdown","metadata":{"id":"1_9PJHQ2eIU1"},"source":["#### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zm8XkkqHeN3B"},"outputs":[],"source":["trainer_manager_elbow.validate(model_elbow, test_loader_elbow)"]},{"cell_type":"markdown","metadata":{"id":"7UAolCZbWoPU"},"source":["### Hand"]},{"cell_type":"markdown","metadata":{"id":"bOoI0L7-ebRG"},"source":["#### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nBgX-qs_fTEJ"},"outputs":[],"source":["train_df_hand, val_df_hand = train_test_split(train_df_hand, test_size=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KtdQlIX-dsu-"},"outputs":[],"source":["train_dataset_hand = Baseline(train_df_hand, transform=train_val_transformer)\n","val_dataset_hand = Baseline(val_df_hand, transform=test_transformer)\n","test_dataset_hand = Baseline(test_df_hand, transform=test_transformer)\n","\n","train_loader_hand = torch.utils.data.DataLoader(train_dataset_hand, collate_fn=data_loader_manager.collate_fn,\n","                                           batch_size=8, shuffle=True, num_workers=6)\n","val_loader_hand = torch.utils.data.DataLoader(val_dataset_hand, collate_fn=data_loader_manager.collate_fn,\n","                                         batch_size=16, num_workers=6)\n","test_loader_hand = torch.utils.data.DataLoader(test_dataset_hand, collate_fn=data_loader_manager.collate_fn,\n","                                         batch_size=16, num_workers=6)\n","\n","loss_hand = Loss(train_dataset_hand.get_label_weight(1), train_dataset_hand.get_label_weight(0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ULtclETOd92T"},"outputs":[],"source":["model_hand = LightingDenseNet(loss_hand)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_9Gix99AeAxQ"},"outputs":[],"source":["hand_path = '/content/baseline/training/hand'\n","\n","trainer_manager_hand = TrainerManager(max_epochs=15)\n","trainer_manager_hand.train(model_hand, train_loader_hand, val_loader_hand, hand_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"10Lwj6hJ5ruN"},"outputs":[],"source":["# Start tensorboard.\n","%reload_ext tensorboard\n","%tensorboard --logdir /content/baseline/training/hand"]},{"cell_type":"markdown","metadata":{"id":"11ZXmXpIee0D"},"source":["#### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NuSp9PAceijh"},"outputs":[],"source":["trainer_manager_hand.validate(model_hand, test_loader_hand)"]},{"cell_type":"markdown","metadata":{"id":"rflc26AAWpVl"},"source":["### Shoulder"]},{"cell_type":"markdown","metadata":{"id":"xM5CO4KCehQO"},"source":["#### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9jqR_KINgYTc"},"outputs":[],"source":["train_df_shoulder, val_df_shoulder = train_test_split(train_df_shoulder, test_size=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fifi_cTdetry"},"outputs":[],"source":["train_dataset_shoulder = Baseline(train_df_shoulder, transform=train_val_transformer)\n","val_dataset_shoulder = Baseline(train_df_shoulder, transform=test_transformer)\n","test_dataset_shoulder = Baseline(test_df_shoulder, transform=test_transformer)\n","\n","train_loader_shoulder = torch.utils.data.DataLoader(train_dataset_shoulder, collate_fn=data_loader_manager.collate_fn,\n","                                           batch_size=8, shuffle=True, num_workers=6)\n","val_loader_shoulder = torch.utils.data.DataLoader(val_dataset_shoulder, collate_fn=data_loader_manager.collate_fn,\n","                                         batch_size=16, num_workers=6)\n","test_loader_shoulder = torch.utils.data.DataLoader(test_dataset_shoulder, collate_fn=data_loader_manager.collate_fn,\n","                                        batch_size=16, num_workers=6)\n","\n","loss_shoulder = Loss(train_dataset_shoulder.get_label_weight(1), train_dataset_shoulder.get_label_weight(0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SK2S-LpAetr9"},"outputs":[],"source":["model_shoulder = LightingDenseNet(loss_shoulder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s7_7P1kqetr9"},"outputs":[],"source":["shoulder_path = '/content/baseline/training/shoulder'\n","\n","trainer_manager_shoulder = TrainerManager(max_epochs=15)\n","trainer_manager_shoulder.train(model_shoulder, train_loader_shoulder, val_loader_shoulder, shoulder_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lamv95pVnPyX"},"outputs":[],"source":["# Start tensorboard.\n","%load_ext tensorboard\n","%tensorboard --logdir /content/baseline/training/shoulder --port=8017"]},{"cell_type":"markdown","metadata":{"id":"9afUDi9Uef7D"},"source":["#### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nypk4s1_gmeO"},"outputs":[],"source":["trainer_manager_shoulder.validate(model_shoulder, test_loader_shoulder)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}